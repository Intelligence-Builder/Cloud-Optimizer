{
  "issue_number": 37,
  "title": "8.3 Security Analysis Integration",
  "body": "# 8.3 Security Analysis Integration\n\n## Parent Epic\nEpic 8: MVP Phase 2 - Expert System (Intelligence-Builder)\n\n## Overview\n\nImplement the integration between Intelligence-Builder (IB) and Cloud Optimizer (CO) security findings. IB analyzes findings to provide expert explanations, prioritization recommendations, and remediation guidance through the chat interface.\n\n## Background\n\nThe security analysis integration bridges scanning results with expert advice:\n- Explain findings in business context\n- Prioritize remediation based on risk\n- Provide compliance-aware recommendations\n- Generate actionable remediation plans\n\n## Requirements\n\n| ID | Requirement | Acceptance Criteria |\n|----|-------------|---------------------|\n| IB-SEC-001 | Finding explanation | Explain any finding in plain language with business impact |\n| IB-SEC-002 | Risk prioritization | Rank findings by risk considering compliance, exploitability |\n| IB-SEC-003 | Remediation planning | Generate step-by-step remediation with code examples |\n| IB-SEC-004 | Compliance correlation | Map findings to specific compliance controls |\n\n## Technical Specification\n\n### Security Analysis Service\n\n```python\n# src/ib_platform/security/analysis_service.py\nfrom anthropic import Anthropic\n\nclass SecurityAnalysisService:\n    \"\"\"Analyze security findings and provide expert guidance.\"\"\"\n\n    ANALYSIS_PROMPT = \"\"\"You are a senior cloud security engineer analyzing AWS security findings.\n\nFor each finding, provide:\n1. Plain language explanation of the risk\n2. Business impact if exploited\n3. Likelihood of exploitation\n4. Compliance implications\n5. Prioritized remediation steps\n6. Example code to fix (Terraform, AWS CLI, or Console steps)\n\nBe specific and actionable. Reference the exact resource and configuration.\"\"\"\n\n    def __init__(\n        self,\n        anthropic_client: Anthropic,\n        findings_service: FindingsService,\n        compliance_service: ComplianceService,\n    ):\n        self.client = anthropic_client\n        self.findings_service = findings_service\n        self.compliance_service = compliance_service\n\n    async def explain_finding(\n        self,\n        tenant_id: UUID,\n        finding_id: UUID,\n    ) -> FindingExplanation:\n        \"\"\"Generate detailed explanation for a finding.\"\"\"\n        finding = await self.findings_service.get_finding(tenant_id, finding_id)\n\n        # Get compliance context\n        compliance_controls = await self.compliance_service.get_controls_for_rule(\n            finding.rule_id\n        )\n\n        prompt = f\"\"\"Analyze this security finding:\n\n**Finding:** {finding.title}\n**Severity:** {finding.severity}\n**Resource:** {finding.resource_type} - {finding.resource_id}\n**Region:** {finding.region}\n**Description:** {finding.description}\n\n**Compliance Frameworks Affected:** {', '.join(finding.compliance_frameworks)}\n**Specific Controls:**\n{self._format_controls(compliance_controls)}\n\nProvide a comprehensive analysis following the structure above.\"\"\"\n\n        response = await self.client.messages.create(\n            model=\"claude-3-5-sonnet-20241022\",\n            max_tokens=1500,\n            system=self.ANALYSIS_PROMPT,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n        )\n\n        return FindingExplanation(\n            finding_id=finding_id,\n            explanation=response.content[0].text,\n            compliance_controls=compliance_controls,\n            generated_at=datetime.utcnow(),\n        )\n\n    async def prioritize_findings(\n        self,\n        tenant_id: UUID,\n        limit: int = 10,\n    ) -> PrioritizedFindings:\n        \"\"\"Prioritize open findings by risk.\"\"\"\n        # Get all open findings\n        findings = await self.findings_service.get_findings(\n            tenant_id,\n            filters=FindingFilters(status=[\"open\"]),\n            pagination=Pagination(limit=100),\n        )\n\n        # Score each finding\n        scored_findings = []\n        for finding in findings.items:\n            score = self._calculate_risk_score(finding)\n            scored_findings.append((finding, score))\n\n        # Sort by score descending\n        scored_findings.sort(key=lambda x: x[1], reverse=True)\n\n        # Get top N\n        top_findings = scored_findings[:limit]\n\n        # Generate prioritization rationale\n        rationale = await self._generate_prioritization_rationale(\n            [f for f, _ in top_findings]\n        )\n\n        return PrioritizedFindings(\n            findings=[\n                PrioritizedFinding(\n                    finding=f,\n                    risk_score=s,\n                    rank=i + 1,\n                )\n                for i, (f, s) in enumerate(top_findings)\n            ],\n            rationale=rationale,\n        )\n\n    def _calculate_risk_score(self, finding: Finding) -> float:\n        \"\"\"Calculate risk score for prioritization.\"\"\"\n        score = 0.0\n\n        # Severity weight (0-40 points)\n        severity_weights = {\n            \"critical\": 40,\n            \"high\": 30,\n            \"medium\": 15,\n            \"low\": 5,\n        }\n        score += severity_weights.get(finding.severity, 0)\n\n        # Compliance weight (0-30 points)\n        high_value_frameworks = [\"HIPAA\", \"PCI-DSS\"]\n        if any(f in finding.compliance_frameworks for f in high_value_frameworks):\n            score += 30\n        elif finding.compliance_frameworks:\n            score += 15\n\n        # Resource type weight (0-20 points)\n        high_risk_resources = [\"iam\", \"s3\", \"rds\"]\n        if any(r in finding.resource_type.lower() for r in high_risk_resources):\n            score += 20\n\n        # Public exposure weight (0-10 points)\n        if \"public\" in finding.title.lower() or \"public\" in finding.description.lower():\n            score += 10\n\n        return score\n\n    async def _generate_prioritization_rationale(\n        self,\n        findings: list[Finding],\n    ) -> str:\n        \"\"\"Generate explanation for prioritization.\"\"\"\n        prompt = f\"\"\"Given these top priority security findings, explain why they should be addressed in this order:\n\n{self._format_findings_for_prompt(findings)}\n\nProvide a brief (2-3 paragraph) rationale focusing on:\n1. Why the top issues are most critical\n2. What the overall security posture indicates\n3. Quick wins that could be addressed first\"\"\"\n\n        response = await self.client.messages.create(\n            model=\"claude-3-5-sonnet-20241022\",\n            max_tokens=500,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n        )\n\n        return response.content[0].text\n\n    async def generate_remediation_plan(\n        self,\n        tenant_id: UUID,\n        finding_ids: list[UUID],\n    ) -> RemediationPlan:\n        \"\"\"Generate comprehensive remediation plan for findings.\"\"\"\n        findings = []\n        for fid in finding_ids:\n            finding = await self.findings_service.get_finding(tenant_id, fid)\n            findings.append(finding)\n\n        prompt = f\"\"\"Generate a remediation plan for these security findings:\n\n{self._format_findings_for_prompt(findings)}\n\nFor each finding provide:\n1. Step-by-step remediation instructions\n2. Terraform code to fix (if applicable)\n3. AWS CLI commands (if applicable)\n4. AWS Console steps\n5. Verification steps to confirm remediation\n\nGroup related findings if they can be fixed together.\"\"\"\n\n        response = await self.client.messages.create(\n            model=\"claude-3-5-sonnet-20241022\",\n            max_tokens=3000,\n            system=\"You are a cloud security engineer creating remediation plans.\",\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n        )\n\n        return RemediationPlan(\n            findings=findings,\n            plan=response.content[0].text,\n            generated_at=datetime.utcnow(),\n        )\n\n    def _format_findings_for_prompt(self, findings: list[Finding]) -> str:\n        \"\"\"Format findings for LLM prompt.\"\"\"\n        lines = []\n        for i, f in enumerate(findings, 1):\n            lines.append(f\"{i}. **{f.title}** ({f.severity})\")\n            lines.append(f\"   Resource: {f.resource_id}\")\n            lines.append(f\"   Compliance: {', '.join(f.compliance_frameworks)}\")\n            lines.append(f\"   Description: {f.description[:200]}\")\n            lines.append(\"\")\n        return \"\\n\".join(lines)\n\n    def _format_controls(self, controls: list[ComplianceControl]) -> str:\n        \"\"\"Format compliance controls for prompt.\"\"\"\n        lines = []\n        for c in controls:\n            lines.append(f\"- {c.control_code}: {c.name}\")\n        return \"\\n\".join(lines)\n```\n\n### Finding Correlation\n\n```python\n# src/ib_platform/security/correlation.py\nclass FindingCorrelator:\n    \"\"\"Correlate related findings for holistic analysis.\"\"\"\n\n    async def find_related(\n        self,\n        finding: Finding,\n        all_findings: list[Finding],\n    ) -> list[Finding]:\n        \"\"\"Find findings related to a given finding.\"\"\"\n        related = []\n\n        for f in all_findings:\n            if f.finding_id == finding.finding_id:\n                continue\n\n            # Same resource\n            if f.resource_id == finding.resource_id:\n                related.append(f)\n                continue\n\n            # Same resource type in same region\n            if (\n                f.resource_type == finding.resource_type\n                and f.region == finding.region\n            ):\n                related.append(f)\n                continue\n\n            # Same compliance framework\n            if set(f.compliance_frameworks) & set(finding.compliance_frameworks):\n                related.append(f)\n\n        return related[:5]  # Top 5 related\n\n    async def cluster_findings(\n        self,\n        findings: list[Finding],\n    ) -> list[FindingCluster]:\n        \"\"\"Group findings into clusters for batch remediation.\"\"\"\n        clusters = {}\n\n        for finding in findings:\n            # Cluster by resource type + severity\n            key = (finding.resource_type, finding.severity)\n            if key not in clusters:\n                clusters[key] = FindingCluster(\n                    resource_type=finding.resource_type,\n                    severity=finding.severity,\n                    findings=[],\n                )\n            clusters[key].findings.append(finding)\n\n        return list(clusters.values())\n```\n\n### Models\n\n```python\n# src/ib_platform/security/models.py\nfrom dataclasses import dataclass\nfrom datetime import datetime\n\n@dataclass\nclass FindingExplanation:\n    finding_id: UUID\n    explanation: str\n    compliance_controls: list[ComplianceControl]\n    generated_at: datetime\n\n\n@dataclass\nclass PrioritizedFinding:\n    finding: Finding\n    risk_score: float\n    rank: int\n\n\n@dataclass\nclass PrioritizedFindings:\n    findings: list[PrioritizedFinding]\n    rationale: str\n\n\n@dataclass\nclass RemediationPlan:\n    findings: list[Finding]\n    plan: str\n    generated_at: datetime\n\n\n@dataclass\nclass FindingCluster:\n    resource_type: str\n    severity: str\n    findings: list[Finding]\n\n    @property\n    def count(self) -> int:\n        return len(self.findings)\n```\n\n## API Endpoints\n\n```\nGET  /api/v1/analysis/findings/:id/explain     # Explain finding\nGET  /api/v1/analysis/findings/prioritize      # Get prioritized findings\nPOST /api/v1/analysis/remediation-plan         # Generate remediation plan\nGET  /api/v1/analysis/findings/:id/related     # Get related findings\nGET  /api/v1/analysis/clusters                 # Get finding clusters\n```\n\n## Files to Create\n\n```\nsrc/ib_platform/security/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 analysis_service.py      # Main analysis service\n\u251c\u2500\u2500 correlation.py           # Finding correlation\n\u251c\u2500\u2500 scoring.py               # Risk scoring\n\u2514\u2500\u2500 models.py                # Data models\n\nsrc/cloud_optimizer/api/routers/\n\u2514\u2500\u2500 analysis.py              # API endpoints\n\ntests/ib_platform/security/\n\u251c\u2500\u2500 test_analysis_service.py\n\u251c\u2500\u2500 test_correlation.py\n\u251c\u2500\u2500 test_scoring.py\n\u2514\u2500\u2500 test_api.py\n```\n\n## Testing Requirements\n\n### Unit Tests\n- [ ] `test_risk_scoring.py` - Risk score calculation\n- [ ] `test_correlation.py` - Finding correlation logic\n- [ ] `test_clustering.py` - Finding clustering\n\n### Integration Tests\n- [ ] `test_analysis_service.py` - Full analysis with mocked LLM\n- [ ] `test_remediation_plan.py` - Plan generation\n\n## Acceptance Criteria Checklist\n\n- [ ] Finding explanations are clear and actionable\n- [ ] Risk score considers severity, compliance, exposure\n- [ ] Prioritization includes rationale\n- [ ] Remediation plans include code examples\n- [ ] Related findings identified correctly\n- [ ] Clusters group similar findings\n- [ ] Compliance controls mapped to findings\n- [ ] API endpoints return correct data\n- [ ] 80%+ test coverage\n\n## Dependencies\n\n- 7.2 Security Scanner (generates findings)\n- 7.4 Findings Management (finding queries)\n- 7.5 Compliance Mapping (compliance context)\n\n## Blocked By\n\n- 7.4 Findings Management\n\n## Blocks\n\n- 8.2 Answer Generation (uses analysis for responses)\n\n## Estimated Effort\n\n1 week\n\n## Labels\n\n`security`, `analysis`, `ib`, `mvp`, `phase-2`, `P0`\n",
  "labels": [
    "security",
    "mvp",
    "phase-2",
    "P0",
    "ib",
    "analysis"
  ],
  "assignees": [],
  "milestone": null,
  "created_at": null,
  "updated_at": null,
  "state": "OPEN",
  "context": {
    "complexity": "medium",
    "effort": "medium",
    "confidence": 0.8,
    "required_expertise": [
      "security",
      "backend"
    ],
    "dependencies": [],
    "related_files": []
  },
  "generated_at": "2025-12-04T12:04:58.961035Z",
  "generated_by": "smart-scaffold-cli",
  "branch_name": "feature/issue-37-83securityanalysisintegration"
}