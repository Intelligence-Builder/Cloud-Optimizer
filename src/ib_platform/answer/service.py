"""Answer generation service using Claude API.

This module provides the AnswerService that generates expert-level security
responses using Claude with context from KB, findings, and documents.
"""

import logging
from typing import Any, AsyncIterator
from uuid import UUID

from anthropic import AsyncAnthropic

from ib_platform.answer.context import AnswerContext, ContextAssembler
from ib_platform.answer.prompts import (
    SECURITY_EXPERT_SYSTEM_PROMPT,
    build_context_message,
)
from ib_platform.kb.service import KnowledgeBaseService

logger = logging.getLogger(__name__)


class AnswerService:
    """Service for generating expert security answers using Claude.

    Uses the Anthropic Claude API to generate responses with rich context from
    knowledge base, findings, and documents. Supports streaming for real-time
    response delivery.

    Example:
        >>> from anthropic import AsyncAnthropic
        >>> client = AsyncAnthropic(api_key="...")
        >>> kb_service = KnowledgeBaseService.get_instance()
        >>> service = AnswerService(client, kb_service)
        >>> async for chunk in service.generate_streaming("How do I secure S3?", nlu_result):
        ...     print(chunk, end="")
    """

    DEFAULT_MODEL = "claude-3-5-sonnet-20241022"
    DEFAULT_MAX_TOKENS = 2000

    def __init__(
        self,
        anthropic_client: AsyncAnthropic,
        kb_service: KnowledgeBaseService,
        findings_service: Any = None,
        document_service: Any = None,
        model: str | None = None,
        max_tokens: int | None = None,
    ) -> None:
        """Initialize the answer service.

        Args:
            anthropic_client: Async Anthropic client for Claude API
            kb_service: Knowledge base service
            findings_service: Optional findings service
            document_service: Optional document service
            model: Optional model override (default: claude-3-5-sonnet-20241022)
            max_tokens: Optional max tokens override (default: 2000)
        """
        self.client = anthropic_client
        self.kb_service = kb_service
        self.findings_service = findings_service
        self.document_service = document_service
        self.model = model or self.DEFAULT_MODEL
        self.max_tokens = max_tokens or self.DEFAULT_MAX_TOKENS

        # Initialize context assembler
        self.context_assembler = ContextAssembler(
            kb_service=kb_service,
            findings_service=findings_service,
            document_service=document_service,
        )

    async def generate_streaming(
        self,
        question: str,
        nlu_result: Any,
        aws_account_id: UUID | None = None,
        conversation_history: list[dict[str, str]] | None = None,
    ) -> AsyncIterator[str]:
        """Generate answer with streaming response.

        Args:
            question: User's question
            nlu_result: NLU processing result with intent and entities
            aws_account_id: Optional AWS account ID for finding queries
            conversation_history: Optional previous conversation messages

        Yields:
            Text chunks as they are generated by Claude

        Example:
            >>> async for chunk in service.generate_streaming("How secure is my S3?", nlu_result):
            ...     print(chunk, end="")
        """
        # Assemble context from various sources
        context = await self.context_assembler.assemble(
            nlu_result=nlu_result,
            aws_account_id=aws_account_id,
            conversation_history=conversation_history,
        )

        # Build messages for Claude API
        messages = self._build_messages(question, context)

        # Stream response from Claude
        try:
            async with self.client.messages.stream(
                model=self.model,
                max_tokens=self.max_tokens,
                system=SECURITY_EXPERT_SYSTEM_PROMPT,
                messages=messages,
            ) as stream:
                async for text in stream.text_stream:
                    yield text

        except Exception as e:
            logger.error(f"Error generating answer: {e}", exc_info=True)
            yield f"\n\n⚠️ Error generating response: {str(e)}\n\nPlease try rephrasing your question."

    async def generate(
        self,
        question: str,
        nlu_result: Any,
        aws_account_id: UUID | None = None,
        conversation_history: list[dict[str, str]] | None = None,
    ) -> str:
        """Generate complete answer (non-streaming).

        Args:
            question: User's question
            nlu_result: NLU processing result with intent and entities
            aws_account_id: Optional AWS account ID for finding queries
            conversation_history: Optional previous conversation messages

        Returns:
            Complete generated answer as string

        Example:
            >>> answer = await service.generate("How do I secure RDS?", nlu_result)
        """
        # Assemble context from various sources
        context = await self.context_assembler.assemble(
            nlu_result=nlu_result,
            aws_account_id=aws_account_id,
            conversation_history=conversation_history,
        )

        # Build messages for Claude API
        messages = self._build_messages(question, context)

        # Get complete response from Claude
        try:
            response = await self.client.messages.create(
                model=self.model,
                max_tokens=self.max_tokens,
                system=SECURITY_EXPERT_SYSTEM_PROMPT,
                messages=messages,
            )

            # Extract text from response
            if response.content:
                return "".join(
                    block.text for block in response.content if hasattr(block, "text")
                )
            return ""

        except Exception as e:
            logger.error(f"Error generating answer: {e}", exc_info=True)
            return f"⚠️ Error generating response: {str(e)}\n\nPlease try rephrasing your question."

    def _build_messages(
        self, question: str, context: AnswerContext
    ) -> list[dict[str, str]]:
        """Build messages array for Claude API.

        Args:
            question: User's question
            context: Assembled context with KB entries, findings, documents

        Returns:
            List of message dictionaries in Claude API format
        """
        messages = []

        # Add conversation history (last 10 messages for context window)
        for msg in context.conversation_history[-10:]:
            messages.append({"role": msg["role"], "content": msg["content"]})

        # Build enriched user message with all context
        user_content = build_context_message(
            question=question,
            kb_entries=context.kb_entries,
            findings=context.findings,
            documents=context.documents,
        )

        messages.append({"role": "user", "content": user_content})

        return messages


def create_answer_service(
    api_key: str,
    kb_service: KnowledgeBaseService,
    findings_service: Any = None,
    document_service: Any = None,
    model: str | None = None,
) -> AnswerService:
    """Factory function to create an AnswerService.

    Args:
        api_key: Anthropic API key
        kb_service: Knowledge base service
        findings_service: Optional findings service
        document_service: Optional document service
        model: Optional model override

    Returns:
        Configured AnswerService instance

    Example:
        >>> service = create_answer_service(
        ...     api_key="sk-ant-...",
        ...     kb_service=kb_service,
        ...     findings_service=findings_service,
        ... )
    """
    client = AsyncAnthropic(api_key=api_key)
    return AnswerService(
        anthropic_client=client,
        kb_service=kb_service,
        findings_service=findings_service,
        document_service=document_service,
        model=model,
    )
